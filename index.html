<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Hand Tracking Voice Bot</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <style>
    body { text-align:center; background:#111; color:#eee; font-family:sans-serif; }
    video, canvas { border:2px solid #444; margin:10px; }
    #controls { margin-top:20px; }
    button { padding:10px 20px; margin:5px; }
  </style>
</head>
<body>
  <h1>ðŸ¤– Hand Tracking Voice Bot</h1>
  <video id="input_video" autoplay playsinline style="display:none;"></video>
  <canvas id="output_canvas" width="640" height="480"></canvas>
  <div id="controls">
    <button onclick="startRecordGesture()">ðŸŽ¥ Rekam Gestur Baru</button>
    <input id="gestureName" placeholder="Nama gestur">
    <input id="gestureResponse" placeholder="Respon suara bot">
    <button onclick="saveGesture()">ðŸ’¾ Simpan Gestur</button>
  </div>
  <p id="status">Status: Menunggu...</p>

<script>
  const videoElement = document.getElementById('input_video');
  const canvasElement = document.getElementById('output_canvas');
  const canvasCtx = canvasElement.getContext('2d');
  const statusEl = document.getElementById('status');

  let recording = false;
  let tempGesture = null;
  let customGestures = []; // {name, response, landmarks}
  let lastSpoken = 0;
  const cooldown = 2500; // 2.5 detik

  function speak(text){
    const now = Date.now();
    if (now - lastSpoken < cooldown) return; // cegah spam
    lastSpoken = now;
    let utter = new SpeechSynthesisUtterance(text);
    speechSynthesis.speak(utter);
  }

  function startRecordGesture(){
    recording = true;
    statusEl.textContent = "Status: Angkat tangan dan tahan untuk merekam gestur...";
  }

  function saveGesture(){
    const name = document.getElementById("gestureName").value;
    const response = document.getElementById("gestureResponse").value;
    if(tempGesture && name && response){
      customGestures.push({ name, response, landmarks: tempGesture });
      statusEl.textContent = `âœ… Gestur "${name}" disimpan dengan respon "${response}"`;
      recording = false;
      tempGesture = null;
    } else {
      alert("Rekam gestur dulu, lalu isi nama dan respon!");
    }
  }

  function compareGestures(g1, g2){
    if(!g1 || !g2) return Infinity;
    let sum = 0;
    for(let i=0;i<g1.length;i++){
      sum += Math.abs(g1[i].x - g2[i].x) + Math.abs(g1[i].y - g2[i].y);
    }
    return sum;
  }

  function onResults(results) {
    canvasCtx.save();
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
    canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

    if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
      const landmarks = results.multiHandLandmarks[0];
      // gambar tangan
      for (let lm of landmarks){
        canvasCtx.beginPath();
        canvasCtx.arc(lm.x*canvasElement.width, lm.y*canvasElement.height, 5, 0, 2*Math.PI);
        canvasCtx.fillStyle = "lime";
        canvasCtx.fill();
      }

      if(recording){
        tempGesture = landmarks.map(lm=>({x:lm.x, y:lm.y}));
        statusEl.textContent = "âœ… Gestur direkam! Isi nama & respon lalu klik Simpan.";
      } else {
        // deteksi gestur terdekat
        if(customGestures.length > 0){
          let current = landmarks.map(lm=>({x:lm.x,y:lm.y}));
          let best = null, minDist=Infinity;
          for(let g of customGestures){
            let d = compareGestures(g.landmarks, current);
            if(d < minDist){ minDist=d; best=g; }
          }
          if(best && minDist < 3.0){ // threshold akurasi
            speak(best.response);
            statusEl.textContent = `ðŸ‘‰ Gestur terdeteksi: ${best.name}`;
          }
        }
      }
    }
    canvasCtx.restore();
  }

  const hands = new Hands({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
  });
  hands.setOptions({
    maxNumHands: 1,
    modelComplexity: 1,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.7
  });
  hands.onResults(onResults);

  const camera = new Camera(videoElement, {
    onFrame: async () => { await hands.send({image: videoElement}); },
    width: 640,
    height: 480
  });
  camera.start();
</script>
</body>
</html>
